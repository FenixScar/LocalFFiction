import csv
import os
import re
import html
from datetime import datetime
import json
import sys
from tqdm import tqdm

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —è–∑—ã–∫–∞
LANGUAGE = 'en'

def clean_text(text):
    """
    –¢—â–∞—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç HTML-—Ç–µ–≥–æ–≤, –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ JSON –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
    """
    if not text or not isinstance(text, str):
        return text

    # –£–¥–∞–ª–µ–Ω–∏–µ HTML-—Ç–µ–≥–æ–≤ —Å –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏
    text = re.sub(r'<[a-zA-Z]+[^>]*>|<\/[a-zA-Z]+>', '', text)
    # –£–¥–∞–ª–µ–Ω–∏–µ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è HTML-—Å—É—â–Ω–æ—Å—Ç–µ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, &nbsp;)
    text = html.unescape(text)
    # –£–¥–∞–ª–µ–Ω–∏–µ –æ—Å—Ç–∞—Ç–∫–æ–≤ —Ä–∞–∑–º–µ—Ç–∫–∏ JSON
    text = re.sub(r'^\s*".*?":\s*"?|"\s*$', '', text)
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–±–µ–ª–æ–≤
    text = ' '.join(text.split()).strip()
    return text

def clean_html_description(html_text):
    """
    –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ HTML-–æ–ø–∏—Å–∞–Ω–∏–π –æ—Ç –≤—Å–µ—Ö —Ç–µ–≥–æ–≤ –∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
    """
    if not html_text or not isinstance(html_text, str):
        return html_text

    # –£–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö HTML-—Ç–µ–≥–æ–≤ –∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
    clean_text = re.sub(r'<[a-zA-Z][^>]*>|<\/[a-zA-Z][^>]*>|<[^>]*$|^[^<]*>', '', html_text)
    # –£–¥–∞–ª–µ–Ω–∏–µ HTML-—Å—É—â–Ω–æ—Å—Ç–µ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, &nbsp; &amp; –∏ —Ç.–¥.)
    clean_text = html.unescape(clean_text)
    # –£–¥–∞–ª–µ–Ω–∏–µ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
    clean_text = re.sub(r'\\["\'\\]', '', clean_text)
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–±–µ–ª–æ–≤
    clean_text = ' '.join(clean_text.split()).strip()
    return clean_text

def format_tags(tags_data):
    """
    –£–ª—É—á—à–µ–Ω–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–≥–æ–≤ —Å —Ç–æ—á–Ω–æ–π –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    """
    if not tags_data or not isinstance(tags_data, list):
        return ""

    # –°–ª–æ–≤–∞—Ä—å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
    CATEGORY_MAP = {
        'character': 'Character',
        'characters': 'Character',
        'genre': 'Genre',
        'genres': 'Genre',
        'series': 'Series',
        'warning': 'Warning',
        'warnings': 'Warning',
        'content': 'Content',
        'language': 'Language',
        'spoiler': 'Spoiler',
        'editor': 'Editor',
        'status': 'Status'
    }

    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Ç–µ–≥–æ–≤ –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    tags_by_category = {}
    for tag in tags_data:
        if not isinstance(tag, dict) or 'type' not in tag or 'name' not in tag:
            continue

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        raw_category = tag['type'].lower().strip()
        category = CATEGORY_MAP.get(raw_category, raw_category.capitalize())

        # –û—á–∏—Å—Ç–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–µ–≥–∞
        tag_name = clean_text(tag['name']).strip()
        if not tag_name:
            continue

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
        if category not in tags_by_category:
            tags_by_category[category] = []
        if tag_name not in tags_by_category[category]:  # –∏–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            tags_by_category[category].append(tag_name)

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –≤—ã–≤–æ–¥–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
    category_order = ['Character', 'Genre', 'Series', 'Warning', 'Content', 'Language']

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å–æ–≥–ª–∞—Å–Ω–æ –ø–æ—Ä—è–¥–∫—É, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –≤ –∫–æ–Ω—Ü–µ
    sorted_categories = sorted(
        tags_by_category.keys(),
        key=lambda x: (category_order.index(x) if x in category_order else len(category_order))
    )

    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    formatted_tags = []
    for category in sorted_categories:
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Ç–µ–≥–æ–≤ –≤–Ω—É—Ç—Ä–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É
        formatted_tags.append(f"{category}: {', '.join(sorted(tags_by_category[category]))}")

    return " | ".join(formatted_tags)

def format_prequel(prequel_data):
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–∏–∫–≤–µ–ª–µ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤—Å–µ—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
    """
    if prequel_data is None or prequel_data in ["null", "None", "none", None]:
        return ""

    if isinstance(prequel_data, bool):
        return str(prequel_data).lower()

    if isinstance(prequel_data, str):
        # –ï—Å–ª–∏ —ç—Ç–æ —á–∏—Å–ª–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ (ID –ø—Ä–∏–∫–≤–µ–ª–∞)
        if prequel_data.isdigit():
            return f"id: {prequel_data}"
        return clean_text(prequel_data)

    if isinstance(prequel_data, (int, float)):
        return f"id: {prequel_data}"

    if isinstance(prequel_data, dict):
        parts = []
        if 'id' in prequel_data:
            parts.append(f"id: {prequel_data['id']}")
        if 'title' in prequel_data:
            parts.append(f"title: {clean_text(prequel_data['title'])}")
        return " | ".join(parts) if parts else ""

    return str(prequel_data)

def extract_title(line):
    """
    –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —á–∏—Å—Ç–æ–≥–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞
    """
    title_match = re.search(r'"title":\s*"([^"]*)"[^}]*"total_num_views"', line)
    if not title_match:
        title_match = re.findall(r'"title":\s*"([^"]*)"', line)
        if title_match:
            return clean_text(title_match[-1])
    else:
        return clean_text(title_match.group(1))
    return ""

def parse_line(line):
    """
    –†–∞–∑–±–æ—Ä —Å—Ç—Ä–æ–∫–∏ —Å –¥–∞–Ω–Ω—ã–º–∏ –∏—Å—Ç–æ—Ä–∏–∏
    """
    data = {}

    try:
        json_data = json.loads("{" + line + "}")
        story_id, story_data = next(iter(json_data.items()))

        data['id'] = story_id
        data['title'] = clean_text(story_data.get('title', ''))

        # –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø–æ–ª–µ–π
        fields_mapping = {
            'description_html': 'description_html',
            'short_description': 'short_description',
            'completion_status': 'completion_status',
            'content_rating': 'content_rating',
            'num_words': 'num_words',
            'rating': 'rating',
            'num_views': 'num_views',
            'num_likes': 'num_likes',
            'num_dislikes': 'num_dislikes',
            'num_comments': 'num_comments',
            'date_published': 'date_published',
            'date_updated': 'date_updated'
        }

        for field, source in fields_mapping.items():
            if source in story_data:
                value = story_data[source]
                if field.endswith('_html'):
                    data[field] = clean_html_description(str(value))
                else:
                    data[field] = clean_text(str(value))

        # –ê–≤—Ç–æ—Ä
        if 'author' in story_data:
            author = story_data['author']
            data['author_name'] = clean_text(author.get('name', ''))
            data['author_id'] = clean_text(str(author.get('id', '')))
            if 'bio_html' in author:
                data['author_bio'] = clean_html_description(author['bio_html'])

        # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
        if 'archive' in story_data and 'path' in story_data['archive']:
            data['archive_path'] = clean_text(story_data['archive']['path'])

        # –¢–µ–≥–∏
        if 'tags' in story_data:
            data['tags'] = format_tags(story_data['tags'])

        # –ü—Ä–∏–∫–≤–µ–ª (–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤)
        if 'prequel' in story_data:
            data['prequel'] = format_prequel(story_data['prequel'])

        return data

    except json.JSONDecodeError:
        return parse_line_fallback(line)

def parse_line_fallback(line):
    """
    –†–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥ —Ä–∞–∑–±–æ—Ä–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º regex —Å –Ω–∞–¥–µ–∂–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Ç–µ–≥–æ–≤
    """
    data = {}

    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ID
    id_match = re.search(r'"(\d+)":\s*{', line)
    if id_match:
        data['id'] = id_match.group(1)

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∏—Å—Ç–æ—Ä–∏–∏
    data['title'] = extract_title(line)

    # –ü–æ–∏—Å–∫ –í–°–ï–• —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π num_words –∏ –≤—ã–±–æ—Ä –ü–û–°–õ–ï–î–ù–ï–ì–û
    num_words_matches = re.findall(r'"num_words":\s*(\d+)', line)
    if num_words_matches:
        data['num_words'] = num_words_matches[-1]  # –±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ

    # –û–ø–∏—Å–∞–Ω–∏—è
    html_fields = {
        'description_html': r'"description_html":\s*"([^"]*)"',
        'short_description': r'"short_description":\s*"([^"]*)"'
    }

    for field, pattern in html_fields.items():
        match = re.search(pattern, line)
        if match:
            data[field] = clean_html_description(match.group(1))

    # –ê–≤—Ç–æ—Ä
    author_match = re.search(r'"author":\s*{.*?"name":\s*"([^"]*)".*?"id":\s*(\d+)', line, re.DOTALL)
    if author_match:
        data['author_name'] = clean_text(author_match.group(1))
        data['author_id'] = clean_text(author_match.group(2))
        bio_match = re.search(r'"bio_html":\s*"([^"]*)"', line)
        if bio_match:
            data['author_bio'] = clean_html_description(bio_match.group(1))

    # –î—Ä—É–≥–∏–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è
    simple_fields = [
        'completion_status', 'content_rating', 'rating',
        'num_views', 'num_likes', 'num_dislikes', 'num_comments',
        'date_published', 'date_updated'
    ]

    for field in simple_fields:
        match = re.search(fr'"{field}":\s*"([^"]*)"', line)
        if not match:
            match = re.search(fr'"{field}":\s*([^,}}\s]+)', line)
        if match:
            value = match.group(1).strip('"')
            data[field] = clean_text(value)

    # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
    path_match = re.search(r'"archive":\s*{.*?"path":\s*"([^"]+)"', line, re.DOTALL)
    if path_match:
        data['archive_path'] = clean_text(path_match.group(1))

    # –¢–µ–≥–∏
    tags_match = re.search(r'"tags":\s*(\[[^\]]*\])', line)
    if tags_match:
        try:
            tags_data = json.loads(tags_match.group(1))
            if isinstance(tags_data, list):
                data['tags'] = format_tags(tags_data)
        except json.JSONDecodeError:
            # –†–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –¥–ª—è —Ä—É—á–Ω–æ–≥–æ —Ä–∞–∑–±–æ—Ä–∞, –µ—Å–ª–∏ JSON –Ω–µ–≤–∞–ª–∏–¥–µ–Ω
            tag_items = re.finditer(r'\{"type":\s*"([^"]*)".*?"name":\s*"([^"]*)"', tags_match.group(1), re.DOTALL)
            tags_list = []
            for tag in tag_items:
                tags_list.append({
                    'type': tag.group(1),
                    'name': tag.group(2)
                })
            if tags_list:
                data['tags'] = format_tags(tags_list)

    # –ü—Ä–∏–∫–≤–µ–ª (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞)
    prequel_match = re.search(r'"prequel":\s*(\{.*?\}|"null"|null|true|false|"[^"]*"|\d+)', line, re.DOTALL)
    if prequel_match:
        prequel_value = prequel_match.group(1)

        if prequel_value in ['"null"', 'null']:
            data['prequel'] = ""
        elif prequel_value in ['true', 'false']:
            data['prequel'] = prequel_value
        elif prequel_value.startswith('"') and prequel_value.endswith('"'):
            data['prequel'] = clean_text(prequel_value[1:-1])
        elif prequel_value.isdigit():
            data['prequel'] = f"id: {prequel_value}"
        else:
            try:
                prequel_data = json.loads(prequel_value)
                data['prequel'] = format_prequel(prequel_data)
            except:
                data['prequel'] = format_prequel(prequel_value)

    return data

def process_fimfiction_log(input_path, output_csv):
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –ª–æ–≥-—Ñ–∞–π–ª–∞ Fimfiction —Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∏ –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
    """

    # –ü–æ–¥—Å—á–µ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ
    print("\nüîç –ü–æ–¥—Å—á–µ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–æ–∫...")
    with open(input_path, 'r', encoding='utf-8') as f:
        total_lines = sum(1 for _ in f)

    print(f"\nüöÄ –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {total_lines:,} —Å—Ç—Ä–æ–∫ –≤ {datetime.now().strftime('%H:%M:%S')}")
    print(f"üìÇ –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {input_path} ({os.path.getsize(input_path) / 1024 / 1024:.1f} MB)")
    print(f"üìù –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {output_csv}")

    fieldnames = [
        'id', 'title', 'author_name', 'author_id', 'author_bio',
        'description_html', 'short_description',
        'completion_status', 'content_rating',
        'tags', 'prequel',
        'num_words', 'rating',
        'num_views', 'num_likes', 'num_dislikes', 'num_comments',
        'date_published', 'date_updated', 'archive_path'
    ]

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    stats = {
        'processed': 0,
        'skipped_empty': 0,
        'skipped_338': 0,
        'skipped_errors': 0,
        'skipped_no_id_title': 0,
        'errors': []
    }

    with open(output_csv, 'w', encoding='utf-8-sig', newline='') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()

        with open(input_path, 'r', encoding='utf-8') as f:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            with tqdm(total=total_lines,
                      desc="‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞",
                      unit="—Å—Ç—Ä–æ–∫–∞",
                      bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]") as pbar:

                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    pbar.update(1)

                    if not line:
                        stats['skipped_empty'] += 1
                        continue

                    if line.startswith('338.1'):
                        stats['skipped_338'] += 1
                        continue

                    try:
                        data = parse_line(line)
                        if 'id' in data and 'title' in data:
                            # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö –ø–æ–ª–µ–π
                            for field in data:
                                if isinstance(data[field], str):
                                    if field.endswith('_html') or field == 'author_bio':
                                        data[field] = clean_html_description(data[field])
                                    else:
                                        data[field] = clean_text(data[field])

                            row = {field: data.get(field, '') for field in fieldnames}
                            writer.writerow(row)
                            stats['processed'] += 1
                        else:
                            stats['skipped_no_id_title'] += 1
                            stats['errors'].append(f"–°—Ç—Ä–æ–∫–∞ {line_num}: –Ω–µ—Ç id –∏–ª–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞")
                    except Exception as e:
                        stats['skipped_errors'] += 1
                        stats['errors'].append(f"–°—Ç—Ä–æ–∫–∞ {line_num}: {str(e)}")

    # –í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    print("\n‚úÖ –ì–æ—Ç–æ–≤–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    print(f"‚îú‚îÄ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['processed']:,}")
    print(f"‚îú‚îÄ –ü—Ä–æ–ø—É—â–µ–Ω–æ –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫: {stats['skipped_empty']:,}")
    print(f"‚îú‚îÄ –ü—Ä–æ–ø—É—â–µ–Ω–æ —Å—Ç—Ä–æ–∫ '338.1': {stats['skipped_338']:,}")
    print(f"‚îú‚îÄ –ü—Ä–æ–ø—É—â–µ–Ω–æ –∏–∑-–∑–∞ –æ—à–∏–±–æ–∫: {stats['skipped_errors']:,}")
    print(f"‚îî‚îÄ –ü—Ä–æ–ø—É—â–µ–Ω–æ (–Ω–µ—Ç id/–∑–∞–≥–æ–ª–æ–≤–∫–∞): {stats['skipped_no_id_title']:,}")

    total_skipped = (stats['skipped_empty'] + stats['skipped_338'] +
                     stats['skipped_errors'] + stats['skipped_no_id_title'])
    print(f"\nüìä –ò—Ç–æ–≥–æ: {stats['processed']:,} –∏–∑ {total_lines:,} —Å—Ç—Ä–æ–∫ ({stats['processed'] / total_lines:.1%})")
    print(f"‚è± –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {datetime.now().strftime('%H:%M:%S')}")
    print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output_csv}")

    # –í—ã–≤–æ–¥ –ø–µ—Ä–≤—ã—Ö 5 –æ—à–∏–±–æ–∫ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    if stats['errors']:
        print("\n‚ö† –ü–µ—Ä–≤—ã–µ 5 –æ—à–∏–±–æ–∫:")
        for err in stats['errors'][:5]:
            print(f"  - {err}")
        if len(stats['errors']) > 5:
            print(f"  ... –∏ –µ—â–µ {len(stats['errors']) - 5} –æ—à–∏–±–æ–∫")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –ª–æ–≥–∞ –æ—à–∏–±–æ–∫ –≤ —Ñ–∞–π–ª
        error_log_path = os.path.splitext(output_csv)[0] + '_errors.log'
        with open(error_log_path, 'w', encoding='utf-8') as err_file:
            err_file.write("\n".join(stats['errors']))
        print(f"üìù –ü–æ–ª–Ω—ã–π –ª–æ–≥ –æ—à–∏–±–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {error_log_path}")

if __name__ == "__main__":
    input_file = 'index.json'
    output_file = 'fimfiction_result.csv'

    process_fimfiction_log(input_file, output_file)